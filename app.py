from flask import Flask, request, jsonify, render_template
import json
import os
import openai # Make sure to uncomment this import

# --- Configuration ---
# Path to the grant data JSON file generated by the previous script
GRANT_DATA_PATH = os.path.join("scripts", "grant_data", "independent_school_district_grants_search_combined.json")

# --- OpenAI API Setup (Replace with your actual key) ---
# ** IMPORTANT: It's highly recommended to use environment variables for API keys **
# 1. Set environment variable on EC2: export OPENAI_API_KEY="YOUR_ACTUAL_KEY"
# 2. Use in code:
openai.api_key = os.getenv("OPENAI_API_KEY")
# OR, for testing ONLY (remove before production):
# openai.api_key = "YOUR_OPENAI_API_KEY" # Replace with your key

# Ensure you have the 'openai' library installed: pip install openai
# Check if the key is loaded
if not openai.api_key:
    print("Warning: OPENAI_API_KEY environment variable not set. OpenAI calls will fail.")


# --- Flask App Initialization ---
app = Flask(__name__)

# --- Global Variable for Grant Data ---
# Load grant data once when the app starts to avoid reloading on every request
grant_data = []
try:
    # Construct the absolute path based on the script's location
    base_dir = os.path.dirname(os.path.abspath(__file__))
    absolute_grant_data_path = os.path.join(base_dir, GRANT_DATA_PATH)
    print(f"Attempting to load grant data from: {absolute_grant_data_path}")
    with open(absolute_grant_data_path, 'r', encoding='utf-8') as f:
        grant_data = json.load(f)
    print(f"Successfully loaded {len(grant_data)} grant records.")
except FileNotFoundError:
    print(f"Error: Grant data file not found at {absolute_grant_data_path}. Chatbot may not have grant context.")
except json.JSONDecodeError:
    print(f"Error: Could not decode JSON from {absolute_grant_data_path}. Check file integrity.")
except Exception as e:
    print(f"An unexpected error occurred loading grant data: {e}")


# --- Helper Function for OpenAI Interaction (IMPLEMENTED) ---
def get_openai_response(user_question, grant_context_str):
    """
    Sends the user question and grant context to OpenAI and returns the response.
    """
    print("--- Preparing OpenAI Request ---")
    print(f"User Question: {user_question}")
    # print(f"Grant Context Snippet: {grant_context_str[:500]}...") # Log snippet if needed

    # Check if API key is configured
    if not openai.api_key:
         print("Error: OpenAI API key not configured.")
         return "Sorry, the chatbot is not configured correctly (missing API key)."

    # Define the system prompt - instructs the AI on its role and limitations
    system_prompt = (
        "You are a helpful assistant specializing in grant information for Independent School Districts. "
        "Your knowledge is based *only* on the grant data provided below. "
        "Answer the user's question concisely based on the provided grant details. "
        "If the information needed to answer the question is not present in the provided data, "
        "clearly state that you don't have that specific information in the current dataset. "
        "Do not make up information or use external knowledge."
    )

    # Construct the messages for the OpenAI API call
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"Grant Data Context:\n```json\n{grant_context_str}\n```\n\nUser Question:\n{user_question}"}
    ]

    try:
        print("Sending request to OpenAI API...")
        # Make the API call using openai.ChatCompletion.create
        # Consider using newer models or the updated client library if preferred
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo", # A cost-effective and capable model
            messages=messages,
            temperature=0.3, # Lower temperature for more factual, less creative responses
            max_tokens=500,  # Limit the length of the response
            # You can add other parameters like top_p if needed
        )
        assistant_response = response.choices[0].message['content'].strip()
        print(f"OpenAI Response Received: {assistant_response[:100]}...") # Log beginning of response
        return assistant_response
    except openai.error.AuthenticationError as e:
         print(f"OpenAI Authentication Error: {e}")
         return "Sorry, there's an issue with the chatbot configuration (Authentication Error)."
    except openai.error.RateLimitError as e:
         print(f"OpenAI Rate Limit Error: {e}")
         return "Sorry, the chatbot is currently experiencing high traffic. Please try again later."
    except openai.error.OpenAIError as e: # Catch other OpenAI specific errors
        print(f"OpenAI API Error: {e}")
        return f"Sorry, I encountered an error trying to reach the AI model ({type(e).__name__})."
    except Exception as e:
        print(f"Generic Error calling OpenAI API: {e}")
        # Consider logging the full traceback here for debugging
        # import traceback
        # traceback.print_exc()
        return "Sorry, I encountered an unexpected error while processing your request."


# --- API Endpoint for Chat ---
@app.route('/chat', methods=['POST'])
def chat():
    """Handles incoming chat messages."""
    try:
        data = request.get_json()
        if not data or 'question' not in data:
            return jsonify({"error": "Missing 'question' in request body"}), 400

        user_question = data['question']
        print(f"Received question: {user_question}")

        # --- Prepare Context for OpenAI ---
        # For now, still sending the first 10 grants.
        # TODO: Implement smarter context selection (e.g., keyword matching, embeddings)
        #       if performance/cost becomes an issue with large context.
        context_to_send = grant_data[:10] # Example: Send first 10 grants
        # Convert context to a string format suitable for the prompt
        context_str = json.dumps(context_to_send, indent=2)

        # --- Get Response (using implemented OpenAI function) ---
        bot_response = get_openai_response(user_question, context_str)

        return jsonify({"answer": bot_response})

    except Exception as e:
        print(f"Error in /chat endpoint: {e}")
        # Provide a generic error message to the user
        return jsonify({"error": "An internal server error occurred."}), 500

# --- Route for the HTML Frontend ---
@app.route('/')
def index():
    """Serves the main HTML page."""
    return render_template('index.html')

# --- Main Execution ---
if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True) # Keep debug=True for now
